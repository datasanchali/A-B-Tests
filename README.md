# Ad Campaign Effectiveness Report

Welcome! This project analyzes how effective a recent digital ad campaign was — helping you understand whether your ads are really driving conversions and when your audience is most engaged.

## Goal

We wanted to answer:
- Does showing ads actually lead to more sign-ups or purchases?
- When are users most active and likely to convert?
- Is our ad spend paying off?

To find out, we ran an **A/B test**:
- **Group A (Control)** saw no ads.
- **Group B (Test)** saw digital ads.

We then compared how many users converted (e.g., signed up or bought something) in each group.

## Findings?

### ✅ Ads Had an Impact
- Users who saw ads **converted more often** than those who didn’t.
- This suggests the campaign had a **positive effect** on user behavior.

### 🕒 Timing Matters
- Most ad views happened on **Mondays and Tuesdays**.
- Peak engagement times were around **10 AM, 2 PM, 6 PM, 8 PM, and 10 PM**.
- This tells us **when to run ads** for the biggest impact.

### 💰 Smarter Budgeting
- The results help identify the **best time slots** for ad placement.
- You can **optimize budget** by focusing on high-engagement periods.

## 📊 What's in the Report?

- Easy-to-read charts showing ad performance by time and day.
- Conversion comparisons between users who saw ads and those who didn’t.
- Insights you can use in **media buying and campaign planning**.

## 🎯 Key Takeaways

- The campaign **worked** — ads boosted user action.
- Focus on **early weekdays** and **evening hours** for future campaigns.
- This type of testing helps ensure **your budget is well spent**.

---

Want to dig deeper or see visual summaries? Just open the notebook file:  
📁 **`Campaign_Effectiveness.ipynb`**
